{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "davCz6A2ZwI_"
      },
      "source": [
        "# **Loading Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XOBi5pXeZnuX",
        "outputId": "81f4bad9-dc60-46ef-915d-49d1595f2afb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne_features\n",
            "  Downloading mne_features-0.3-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mne_features) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mne_features) (1.11.4)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from mne_features) (0.58.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from mne_features) (1.2.2)\n",
            "Collecting mne (from mne_features)\n",
            "  Downloading mne-1.7.1-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (from mne_features) (1.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from mne_features) (2.0.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne->mne_features) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne->mne_features) (3.1.4)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne->mne_features) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from mne->mne_features) (3.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne->mne_features) (24.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne->mne_features) (1.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne->mne_features) (4.66.4)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->mne_features) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->mne_features) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->mne_features) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->mne_features) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->mne_features) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->mne_features) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne->mne_features) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne->mne_features) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne->mne_features) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne->mne_features) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne->mne_features) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne->mne_features) (3.1.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne->mne_features) (4.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne->mne_features) (2.31.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->mne_features) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne->mne_features) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->mne_features) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->mne_features) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->mne_features) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->mne_features) (2024.6.2)\n",
            "Installing collected packages: mne, mne_features\n",
            "Successfully installed mne-1.7.1 mne_features-0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install mne_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4DdHhR82Ck8T",
        "outputId": "80310cf2-ac9d-470b-b8fa-48f3b379a848"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.7.1-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.4)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from mne) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (24.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from mne) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (4.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (2.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->mne) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.6.2)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-1.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install mne"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ds9liLyZvAA",
        "outputId": "78ee8e57-4932-4346-a46b-149899deb30a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'mne'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2d4bb13dc32f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmne\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mne'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import mne\n",
        "import numpy as np\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "Nqw-3_XOgi8E",
        "outputId": "a7a80097-0cb0-46cf-97d1-3b67d3b52e10"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         )\n\u001b[0;32m--> 283\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0HNFR27FAUXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw1 = mne.io.read_raw_curry('/content/drive/MyDrive/Data/subject1/motor1.dat')\n",
        "raw2 = mne.io.read_raw_curry('/content/drive/MyDrive/Data/subject1/motor2.dat')\n",
        "raw3 = mne.io.read_raw_curry('/content/drive/MyDrive/Data/subject1/motor3.dat')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEeeOOk0rROw",
        "outputId": "47fbdc16-9660-47d9-e25f-97b386ca305f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Leaving device<->head transform as None (no landmarks found)\n",
            "Event file found. Extracting Annotations from /content/drive/MyDrive/Data/subject1/motor1.ceo...\n",
            "Leaving device<->head transform as None (no landmarks found)\n",
            "Event file found. Extracting Annotations from /content/drive/MyDrive/Data/subject1/motor2.ceo...\n",
            "Leaving device<->head transform as None (no landmarks found)\n",
            "Event file found. Extracting Annotations from /content/drive/MyDrive/Data/subject1/motor3.ceo...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_S1 = mne.concatenate_raws([raw1,raw2,raw3])\n",
        "del raw1, raw2, raw3"
      ],
      "metadata": {
        "id": "kumlTlavXfiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_S2 = mne.io.read_raw_curry('/content/drive/MyDrive/Data/subject2/motor.dat')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nkeSNB_XLWh",
        "outputId": "825fe88b-704f-4b62-996a-445fe20590ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Leaving device<->head transform as None (no landmarks found)\n",
            "Event file found. Extracting Annotations from /content/drive/MyDrive/Data/subject2/motor.ceo...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_S3 = mne.io.read_raw_curry('/content/drive/MyDrive/Data/subject3/motor.dat')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gpzZE-AXTd_",
        "outputId": "c097a02c-c3e9-4726-b8f5-17e2b47180da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Leaving device<->head transform as None (no landmarks found)\n",
            "Event file found. Extracting Annotations from /content/drive/MyDrive/Data/subject3/motor.ceo...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_S4 = mne.io.read_raw_curry('/content/drive/MyDrive/Data/subject4/motor.dat')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69G8xlFeXVrL",
        "outputId": "3e3b97b9-df98-4dad-ec98-b54d013ba72d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Leaving device<->head transform as None (no landmarks found)\n",
            "Event file found. Extracting Annotations from /content/drive/MyDrive/Data/subject4/motor.ceo...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw1 = mne.io.read_raw_curry('/content/drive/MyDrive/Data/subject5/Motor1.dat')\n",
        "raw2 = mne.io.read_raw_curry('/content/drive/MyDrive/Data/subject5/Motor2.dat')\n",
        "raw3 = mne.io.read_raw_curry('/content/drive/MyDrive/Data/subject5/Motor3.dat')\n",
        "raw4 = mne.io.read_raw_curry('/content/drive/MyDrive/Data/subject5/Motor4.dat')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7le1HFpXXra",
        "outputId": "07e78d6b-b539-4dbc-f683-3161b55a10c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Leaving device<->head transform as None (no landmarks found)\n",
            "Event file found. Extracting Annotations from /content/drive/MyDrive/Data/subject5/Motor1.ceo...\n",
            "Leaving device<->head transform as None (no landmarks found)\n",
            "Event file found. Extracting Annotations from /content/drive/MyDrive/Data/subject5/Motor2.ceo...\n",
            "Leaving device<->head transform as None (no landmarks found)\n",
            "Event file found. Extracting Annotations from /content/drive/MyDrive/Data/subject5/Motor3.ceo...\n",
            "Leaving device<->head transform as None (no landmarks found)\n",
            "Event file found. Extracting Annotations from /content/drive/MyDrive/Data/subject5/Motor4.ceo...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_S5 = mne.concatenate_raws([raw1,raw2,raw3,raw4])\n",
        "del raw1, raw2, raw3, raw4"
      ],
      "metadata": {
        "id": "ekHbcyuBYJC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw1 = mne.io.read_raw_curry('/content/drive/MyDrive/Data/subject6/Motor1.dat')\n",
        "raw2 = mne.io.read_raw_curry('/content/drive/MyDrive/Data/subject6/Motor2.dat')\n",
        "raw3 = mne.io.read_raw_curry('/content/drive/MyDrive/Data/subject6/Motor3.dat')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60_78A4WXa98",
        "outputId": "c99ce7f4-523f-4985-c998-716a9d499765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Leaving device<->head transform as None (no landmarks found)\n",
            "Event file found. Extracting Annotations from /content/drive/MyDrive/Data/subject6/Motor1.ceo...\n",
            "Leaving device<->head transform as None (no landmarks found)\n",
            "Event file found. Extracting Annotations from /content/drive/MyDrive/Data/subject6/Motor2.ceo...\n",
            "Leaving device<->head transform as None (no landmarks found)\n",
            "Event file found. Extracting Annotations from /content/drive/MyDrive/Data/subject6/Motor3.ceo...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_S6 = mne.concatenate_raws([raw1,raw2,raw3])\n",
        "del raw1, raw2, raw3"
      ],
      "metadata": {
        "id": "BlH1kuY6Ypte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoching (raw):\n",
        "  raw.set_channel_types({\"RF\":'eeg',\"RB\":'eeg' , \"ROU\":'eeg',\"ROD\":'eeg' , \"LF\":'eeg',\"LB\" :'eeg', \"LOU\":'eeg',\"LOD\":'eeg'})\n",
        "\n",
        "  raw.load_data()\n",
        "  raw.resample(250, npad=\"auto\")\n",
        "  raw.filter(l_freq=1.0, h_freq=38.0)\n",
        "\n",
        "\n",
        "  events_from_annot, event_dict = mne.events_from_annotations(raw)\n",
        "\n",
        "  event_dict = {'1':1,'2':2}\n",
        "  reject_criteria = dict(eeg=800e-6)\n",
        "\n",
        "  epochs = mne.Epochs(raw, events_from_annot, event_id=event_dict, tmin=-1, tmax=2-.01, reject=reject_criteria, baseline = (-1,-0.5), preload=True)\n",
        "\n",
        "  return epochs"
      ],
      "metadata": {
        "id": "r4qBLoFdIhaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "2-.01"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rouqWVGO0g7x",
        "outputId": "4ca4e3f7-1df4-499e-d87e-70021c0acf79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.99"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (1,7):\n",
        "  raw = globals()[f\"raw_S{i}\"].copy()\n",
        "  if i == 4:\n",
        "    raw.load_data()\n",
        "    raw.info['bads']=['FP1']\n",
        "    raw.interpolate_bads()\n",
        "  globals()[f\"epochs_subject{i}\"] = epoching(raw)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhTRC2h4LxC3",
        "outputId": "660a627a-4915-4bd3-c4d5-972ee42aeda2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading 0 ... 2989099  =      0.000 ...  2989.099 secs...\n",
            "Filtering raw data in 3 contiguous segments\n",
            "Setting up band-pass filter from 1 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 1.00\n",
            "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 825 samples (3.300 s)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Used Annotations descriptions: ['1', '2', '700010']\n",
            "Not setting metadata\n",
            "240 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 240 events and 749 original time points ...\n",
            "0 bad epochs dropped\n",
            "Reading 0 ... 2031599  =      0.000 ...  2031.599 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 1 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 1.00\n",
            "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 825 samples (3.300 s)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Used Annotations descriptions: ['1', '2']\n",
            "Not setting metadata\n",
            "160 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 160 events and 749 original time points ...\n",
            "0 bad epochs dropped\n",
            "Reading 0 ... 1942099  =      0.000 ...  1942.099 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 1 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 1.00\n",
            "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 825 samples (3.300 s)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Used Annotations descriptions: ['1', '2', '800000', '800001']\n",
            "Not setting metadata\n",
            "160 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 160 events and 749 original time points ...\n",
            "    Rejecting  epoch based on EEG : ['ROU']\n",
            "    Rejecting  epoch based on EEG : ['POO12h']\n",
            "    Rejecting  epoch based on EEG : ['POO12h']\n",
            "    Rejecting  epoch based on EEG : ['POO12h']\n",
            "    Rejecting  epoch based on EEG : ['POO12h']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB', 'ROU']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB', 'ROU']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB', 'ROU']\n",
            "    Rejecting  epoch based on EEG : ['LB', 'ROU']\n",
            "    Rejecting  epoch based on EEG : ['LB', 'ROU']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB', 'ROU']\n",
            "    Rejecting  epoch based on EEG : ['LB', 'ROU']\n",
            "    Rejecting  epoch based on EEG : ['LB', 'ROU']\n",
            "    Rejecting  epoch based on EEG : ['LB', 'ROU']\n",
            "    Rejecting  epoch based on EEG : ['LB', 'ROU']\n",
            "    Rejecting  epoch based on EEG : ['LB', 'ROU']\n",
            "    Rejecting  epoch based on EEG : ['LB', 'ROU']\n",
            "    Rejecting  epoch based on EEG : ['ROU']\n",
            "    Rejecting  epoch based on EEG : ['ROU']\n",
            "    Rejecting  epoch based on EEG : ['ROU']\n",
            "    Rejecting  epoch based on EEG : ['LB', 'ROU']\n",
            "    Rejecting  epoch based on EEG : ['LB', 'ROU']\n",
            "    Rejecting  epoch based on EEG : ['LB', 'ROU']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB', 'ROU']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "    Rejecting  epoch based on EEG : ['LB']\n",
            "62 bad epochs dropped\n",
            "Reading 0 ... 982299  =      0.000 ...   982.299 secs...\n",
            "Setting channel interpolation method to {'eeg': 'spline'}.\n",
            "Interpolating bad channels.\n",
            "    Automatic origin fit: head of radius 96.5 mm\n",
            "Computing interpolation matrix from 121 sensor positions\n",
            "Interpolating 1 sensors\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 1 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 1.00\n",
            "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 825 samples (3.300 s)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Used Annotations descriptions: ['1', '2', '800000', '800001']\n",
            "Not setting metadata\n",
            "80 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 80 events and 749 original time points ...\n",
            "    Rejecting  epoch based on EEG : ['FT9']\n",
            "1 bad epochs dropped\n",
            "Reading 0 ... 3217899  =      0.000 ...  3217.899 secs...\n",
            "Filtering raw data in 3 contiguous segments\n",
            "Setting up band-pass filter from 1 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 1.00\n",
            "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 825 samples (3.300 s)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Used Annotations descriptions: ['1', '2']\n",
            "Not setting metadata\n",
            "240 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 240 events and 749 original time points ...\n",
            "0 bad epochs dropped\n",
            "Reading 0 ... 3217899  =      0.000 ...  3217.899 secs...\n",
            "Filtering raw data in 3 contiguous segments\n",
            "Setting up band-pass filter from 1 - 38 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 1.00\n",
            "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
            "- Upper passband edge: 38.00 Hz\n",
            "- Upper transition bandwidth: 9.50 Hz (-6 dB cutoff frequency: 42.75 Hz)\n",
            "- Filter length: 825 samples (3.300 s)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Used Annotations descriptions: ['1', '2']\n",
            "Not setting metadata\n",
            "240 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 240 events and 749 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_subject1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "9w45qcRvM6y3",
        "outputId": "95f08b9a-84c5-45f8-cb5e-75b4a84ea330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Epochs |  240 events (all good), -1 – 1.992 s, baseline -1 – -0.5 s, ~181.2 MB, data loaded,\n",
              " '1': 120\n",
              " '2': 120>"
            ],
            "text/html": [
              "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
              "    <tr>\n",
              "        <th>Number of events</th>\n",
              "        <td>240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>Events</th>\n",
              "        \n",
              "        <td>1: 120<br/>2: 120</td>\n",
              "        \n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>Time range</th>\n",
              "        <td>-1.000 – 1.992 s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>Baseline</th>\n",
              "        <td>-1.000 – -0.500 s</td>\n",
              "    </tr>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def exponential_moving_standardization_multichannel(raw, alpha=0.001):\n",
        "\n",
        "    \"\"\"\n",
        "    Applies Exponential Moving Standardization (EMS) to multi-channel EEG data.\n",
        "\n",
        "    Parameters:\n",
        "    - signals: 3D numpy array of shape (num_epochs, num_channels, num_samples)\n",
        "      Each slice signals[i] represents the EEG signals from all channels for epoch i.\n",
        "    - alpha: Smoothing factor for the exponential moving average.\n",
        "\n",
        "    Returns:\n",
        "    - standardized_signals: 3D numpy array of shape (num_epochs, num_channels, num_samples)\n",
        "      The standardized EEG signals.\n",
        "    \"\"\"\n",
        "    raw.load_data()\n",
        "    raw_copy = raw.copy()\n",
        "    signals = raw_copy.get_data()\n",
        "    num_epochs, num_channels, num_samples = signals.shape\n",
        "    emm = np.zeros((num_epochs, num_channels, num_samples))\n",
        "    emv = np.zeros((num_epochs, num_channels, num_samples))\n",
        "    ems = np.zeros((num_epochs, num_channels, num_samples))\n",
        "    standardized_signals = np.zeros((num_epochs, num_channels, num_samples))\n",
        "\n",
        "    emm[:, :, 0] = signals[:, :, 0]\n",
        "    emv[:, :, 0] = 0\n",
        "\n",
        "    for ep in range(num_epochs):\n",
        "        for ch in range(num_channels):\n",
        "            for t in range(1, num_samples):\n",
        "                emm[ep, ch, t] = alpha * signals[ep, ch, t] + (1 - alpha) * emm[ep, ch, t-1]\n",
        "                emv[ep, ch, t] = alpha * (signals[ep, ch, t] - emm[ep, ch, t])**2 + (1 - alpha) * emv[ep, ch, t-1]\n",
        "                ems[ep, ch, t] = np.sqrt(emv[ep, ch, t])\n",
        "                standardized_signals[ep, ch, t] = (signals[ep, ch, t] - emm[ep, ch, t]) / (ems[ep, ch, t] + 1e-8)  # Avoid division by zero\n",
        "\n",
        "    raw_copy._data = standardized_signals\n",
        "    return raw_copy"
      ],
      "metadata": {
        "id": "nBgCHJbd1kn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (1,7):\n",
        "  raw = globals()[f\"epochs_subject{i}\"].copy()\n",
        "  globals()[f\"epochs_subject_normalized{i}\"] = exponential_moving_standardization_multichannel(raw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G75Ev9t9dUXE",
        "outputId": "3ff438b1-98a8-420e-9cdc-4a5eaeea711e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-70854710744e>:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  signals = raw_copy.get_data()\n",
            "<ipython-input-41-70854710744e>:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  signals = raw_copy.get_data()\n",
            "<ipython-input-41-70854710744e>:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  signals = raw_copy.get_data()\n",
            "<ipython-input-41-70854710744e>:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  signals = raw_copy.get_data()\n",
            "<ipython-input-41-70854710744e>:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  signals = raw_copy.get_data()\n",
            "<ipython-input-41-70854710744e>:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  signals = raw_copy.get_data()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def different_combinations_of_subjects_and_electrodes (subject_ids):\n",
        "\n",
        "  raw_epochs_pooled = mne.concatenate_epochs([globals()[f\"epochs_subject_normalized{subject_id}\"] for subject_id in subject_ids])\n",
        "\n",
        "  scalp_epochs = raw_epochs_pooled.copy().drop_channels(['ROD','RF','RB','LOD','LF','LB','LOU','ROU','Trigger','10'])\n",
        "\n",
        "  electrodes_of_interest = ['ROD','RF','RB','LOD','LF','LB']\n",
        "  ear_REF_epochs = raw_epochs_pooled.copy().pick_channels(electrodes_of_interest)\n",
        "  channel_types = {ch: 'eeg' for ch in electrodes_of_interest}\n",
        "  ear_REF_epochs.set_channel_types(channel_types)\n",
        "\n",
        "### Ear referenced to scalp REF:\n",
        "### Ear referenced to Contra:\n",
        "\n",
        "  electrodes_of_interest = ['ROD','RF','RB','LOD','LF','LB','LOU','ROU']\n",
        "  ear_contra_epochs = raw_epochs_pooled.copy().pick(electrodes_of_interest)\n",
        "  channel_types = {ch: 'eeg' for ch in electrodes_of_interest}\n",
        "  ear_contra_epochs.set_channel_types(channel_types)\n",
        "\n",
        "  rou_electrodes = ['ROD', 'RF', 'RB']\n",
        "  lou_electrodes = ['LOD', 'LF', 'LB']\n",
        "\n",
        "  # Re-reference to 'LOU'\n",
        "\n",
        "  for electrode in rou_electrodes:\n",
        "    ear_contra_epochs._data[ear_contra_epochs.ch_names.index(electrode), :] -= ear_contra_epochs._data[ear_contra_epochs.ch_names.index('LOU'), :]\n",
        "\n",
        "  # Re-reference to 'ROU'\n",
        "\n",
        "  for electrode in lou_electrodes:\n",
        "    ear_contra_epochs._data[ear_contra_epochs.ch_names.index(electrode), :] -= ear_contra_epochs._data[ear_contra_epochs.ch_names.index('ROU'), :]\n",
        "\n",
        "  ### Ear referenced to IPSI:\n",
        "\n",
        "  electrodes_of_interest = ['ROD','RF','RB','LOD','LF','LB','LOU','ROU']\n",
        "  ear_ipsi_epochs = raw_epochs_pooled.copy().pick(electrodes_of_interest)\n",
        "  channel_types = {ch: 'eeg' for ch in electrodes_of_interest}\n",
        "  ear_ipsi_epochs.set_channel_types(channel_types)\n",
        "\n",
        "  # Re-reference to 'ROU'\n",
        "  for electrode in rou_electrodes:\n",
        "    ear_ipsi_epochs._data[ear_ipsi_epochs.ch_names.index(electrode), :] -= ear_ipsi_epochs._data[ear_ipsi_epochs.ch_names.index('ROU'), :]\n",
        "\n",
        "  # Re-reference to 'LOU'\n",
        "  for electrode in lou_electrodes:\n",
        "    ear_ipsi_epochs._data[ear_ipsi_epochs.ch_names.index(electrode), :] -= ear_ipsi_epochs._data[ear_ipsi_epochs.ch_names.index('LOU'), :]\n",
        "  ###  near Ear:\n",
        "  electrodes_of_interest = ['T7', 'T8', 'T9', 'T10']\n",
        "  near_ear_epochs = raw_epochs_pooled.copy().pick(electrodes_of_interest)\n",
        "  channel_types = {ch: 'eeg' for ch in electrodes_of_interest}\n",
        "  near_ear_epochs.set_channel_types(channel_types)\n",
        "\n",
        "  return scalp_epochs, ear_REF_epochs, ear_contra_epochs, ear_ipsi_epochs, near_ear_epochs"
      ],
      "metadata": {
        "id": "YR0lgAcV5pvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scalp_epochs_subject6, ear_REF_epochs_subject6, ear_contra_epochs_subject6, ear_ipsi_epochs_subject6, near_ear_epochs_subject6 = different_combinations_of_subjects_and_electrodes ([6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AgpRFxiWvr3",
        "outputId": "9ef3ae83-307f-4997-9201-b9c4f690aa89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-109-45a57a5a5311>:3: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
            "  raw_epochs_pooled = mne.concatenate_epochs([globals()[f\"epochs_subject_normalized{subject_id}\"] for subject_id in subject_ids])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not setting metadata\n",
            "240 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pbVRBvlsXU2v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EEGNet**"
      ],
      "metadata": {
        "id": "BtrfKK5c9a0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "from torchvision import transforms\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader, TensorDataset, SubsetRandomSampler\n",
        "\n",
        "# Scikit-Learn\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import confusion_matrix\n"
      ],
      "metadata": {
        "id": "NUcD3Od__CYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "batch_size = 8\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "data_train = torch.tensor(np.float32(ear_REF_epochs))\n",
        "labels_train = ear_REF_epochs.copy().events[:,-1]-1\n",
        "\n",
        "\n",
        "# Converting to Tensor\n",
        "X_train = torch.Tensor(data_train).unsqueeze(1).to(device)\n",
        "y_train = torch.LongTensor(labels_train).to(device)\n",
        "\n",
        "# Creating Tensor Dataset\n",
        "train_dataset = TensorDataset(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "DU6a29fp-FRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_test = torch.Tensor(np.float32(ear_REF_epochs_subject6.get_data()))\n",
        "labels_test = ear_REF_epochs_subject6.copy().events[:,-1]-1\n",
        "\n",
        "X_test = torch.Tensor(data_test).unsqueeze(1).to(device)\n",
        "y_test = torch.LongTensor(labels_test).to(device)\n",
        "\n",
        "test_dataset = TensorDataset(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUeNmP9kXsBn",
        "outputId": "d6950f71-3666-481e-992c-4f8585c10a7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-114-9fd45cc79ae0>:1: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  data_test = torch.Tensor(np.float32(ear_REF_epochs_subject6.get_data()))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EEGNet(nn.Module): # EEGNET-8,2\n",
        "    def __init__(self,  chans=122, classes=2, time_points=749, f1=8, f2=16, d=2,\n",
        "                 dropoutRate=0.5, max_norm1=1, max_norm2=0.25):\n",
        "        super(EEGNet, self).__init__()\n",
        "        # Calculating FC input features\n",
        "        linear_input_size = (time_points//32)*f2\n",
        "\n",
        "        # Temporal Filters\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(1, f1, (1, 32), padding='same', bias=False),\n",
        "            nn.BatchNorm2d(f1),\n",
        "            # nn.BatchNorm2d(f1, momentum=0.01, eps=1e-3),\n",
        "        )\n",
        "        # Spatial Filters\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Conv2d(f1, d * f1, (chans, 1), groups=f1, bias=False), # Depthwise Conv\n",
        "            nn.BatchNorm2d(d * f1),\n",
        "            nn.ELU(),\n",
        "            nn.AvgPool2d((1, 4)),\n",
        "            nn.Dropout(dropoutRate)\n",
        "        )\n",
        "        self.block3 = nn.Sequential(\n",
        "            nn.Conv2d(d * f1, f2, (1, 16),  groups=f2, bias=False, padding='same'), # Separable Conv\n",
        "            nn.Conv2d(f2, f2, kernel_size=1, bias=False), # Pointwise Conv\n",
        "            nn.BatchNorm2d(f2),\n",
        "            nn.ELU(),\n",
        "            nn.AvgPool2d((1, 8)),\n",
        "            nn.Dropout(dropoutRate)\n",
        "        )\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(linear_input_size, classes)\n",
        "\n",
        "        # Apply max_norm constraint to the depthwise layer in block2\n",
        "        self._apply_max_norm(self.block2[0], max_norm1)\n",
        "\n",
        "        # Apply max_norm constraint to the linear layer\n",
        "        self._apply_max_norm(self.fc, max_norm2)\n",
        "\n",
        "    def _apply_max_norm(self, layer, max_norm):\n",
        "        for name, param in layer.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                param.data = torch.renorm(param.data, p=2, dim=0, maxnorm=max_norm)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "qMFyLJ0R_vWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ear_REF_epochs.get_data().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPo_ztFqR2ga",
        "outputId": "19f788f7-c35f-4802-bc83-149885b43e68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-96-ecb1b37247f7>:1: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  ear_REF_epochs.get_data().shape\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(817, 6, 749)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = (1, 6, 749)\n",
        "eegnet_model = EEGNet(chans=6).to(device)\n",
        "summary(eegnet_model, input_size)\n",
        "\n",
        "\n",
        "\n",
        "learning_rate = 0.0001\n",
        "optimizer = optim.Adam(eegnet_model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    eegnet_model.train()\n",
        "    X_train, y_train = shuffle(X_train, y_train)\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        inputs = X_train[i:i+batch_size].to(device)\n",
        "        labels = y_train[i:i+batch_size].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = eegnet_model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    if epoch%5==0:\n",
        "\n",
        "        eegnet_model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for i in range(len(X_train)):\n",
        "                inputs = X_train[i:i+1].to(device)\n",
        "                labels = y_train[i:i+1].to(device)\n",
        "                outputs = eegnet_model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = (correct / total)*100\n",
        "        print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "torch.save(eegnet_model, 'eegnet_model_in_ear_REF.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42chlz5B_0JJ",
        "outputId": "fcb410bc-9693-4871-a263-9b81f36e3d2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 6, 749]             256\n",
            "       BatchNorm2d-2            [-1, 8, 6, 749]              16\n",
            "            Conv2d-3           [-1, 16, 1, 749]              96\n",
            "       BatchNorm2d-4           [-1, 16, 1, 749]              32\n",
            "               ELU-5           [-1, 16, 1, 749]               0\n",
            "         AvgPool2d-6           [-1, 16, 1, 187]               0\n",
            "           Dropout-7           [-1, 16, 1, 187]               0\n",
            "            Conv2d-8           [-1, 16, 1, 187]             256\n",
            "            Conv2d-9           [-1, 16, 1, 187]             256\n",
            "      BatchNorm2d-10           [-1, 16, 1, 187]              32\n",
            "              ELU-11           [-1, 16, 1, 187]               0\n",
            "        AvgPool2d-12            [-1, 16, 1, 23]               0\n",
            "          Dropout-13            [-1, 16, 1, 23]               0\n",
            "          Flatten-14                  [-1, 368]               0\n",
            "           Linear-15                    [-1, 2]             738\n",
            "================================================================\n",
            "Total params: 1,682\n",
            "Trainable params: 1,682\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.02\n",
            "Forward/backward pass size (MB): 0.97\n",
            "Params size (MB): 0.01\n",
            "Estimated Total Size (MB): 0.99\n",
            "----------------------------------------------------------------\n",
            "Test Accuracy: 53.98%\n",
            "Test Accuracy: 63.04%\n",
            "Test Accuracy: 70.75%\n",
            "Test Accuracy: 68.54%\n",
            "Test Accuracy: 72.22%\n",
            "Test Accuracy: 73.56%\n",
            "Test Accuracy: 73.56%\n",
            "Test Accuracy: 74.17%\n",
            "Test Accuracy: 74.91%\n",
            "Test Accuracy: 75.76%\n",
            "Test Accuracy: 76.25%\n",
            "Test Accuracy: 75.89%\n",
            "Test Accuracy: 76.50%\n",
            "Test Accuracy: 76.13%\n",
            "Test Accuracy: 76.01%\n",
            "Test Accuracy: 75.52%\n",
            "Test Accuracy: 75.76%\n",
            "Test Accuracy: 76.87%\n",
            "Test Accuracy: 76.62%\n",
            "Test Accuracy: 75.89%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eegnet_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for i in range(len(X_test)):\n",
        "    inputs = X_test[i:i+1].to(device)\n",
        "    labels = y_test[i:i+1].to(device)\n",
        "    outputs = eegnet_model(inputs)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = (correct / total)*100\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EO4Hd9DSnZ8",
        "outputId": "a3c26854-419c-4cfb-fe55-29ed5cb3aea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 62.08%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxF-LzYwWL4_",
        "outputId": "888b4f0d-a2df-40a5-d63f-e65329711178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0216, 0.1280]])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.max(outputs.data, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkgLzMWuSsOH",
        "outputId": "ae1eef38-77aa-4fe5-d048-2866deecaf0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.max(\n",
              "values=tensor([0.1280]),\n",
              "indices=tensor([1]))"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wedpTkhVSqIe",
        "outputId": "6573b538-25de-4899-fc70-114354228deb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1])"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lzOMcPFTWZzb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}